{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16cc99d1-1bfa-4c54-aa9f-6f0886cb9fc4",
   "metadata": {},
   "source": [
    "## 13 APRIL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544eff54-ba1f-461c-80a0-a4d913e64c09",
   "metadata": {},
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "\n",
    "\n",
    "   - A1. Random Forest Regressor is a machine learning algorithm that belongs to the ensemble learning family. It is used for regression tasks, which involve predicting a continuous numerical output. Random Forest Regressor builds a collection of decision trees during training and uses them to make predictions by aggregating the results from individual trees.\n",
    "\n",
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "\n",
    "\n",
    "   - A2. Random Forest Regressor reduces overfitting through two main mechanisms:\n",
    "     - Bagging: It builds multiple decision trees on different subsets of the training data with replacement. This diversity reduces the risk of any single tree overfitting the data.\n",
    "     - Feature Randomization: It selects a random subset of features for each tree split, which further reduces the tendency of trees to overfit to specific features or noise in the data.\n",
    "\n",
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\n",
    "\n",
    "   - A3. Random Forest Regressor aggregates predictions by taking the average (mean) of the individual predictions from multiple decision trees. In the case of regression tasks, this averaging process produces the final continuous numerical prediction.\n",
    "\n",
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "\n",
    "\n",
    "   - A4. Some common hyperparameters of Random Forest Regressor include:\n",
    "     - Number of trees (n_estimators).\n",
    "     - Maximum depth of individual trees (max_depth).\n",
    "     - Minimum number of samples required to split a node (min_samples_split).\n",
    "     - Minimum number of samples required in a leaf node (min_samples_leaf).\n",
    "     - Maximum number of features considered for each split (max_features).\n",
    "     - Random state (random_state) for reproducibility.\n",
    "\n",
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "\n",
    "\n",
    "   - A5. The main differences between Random Forest Regressor and Decision Tree Regressor are:\n",
    "     - Number of Models: Random Forest consists of multiple decision trees, while Decision Tree Regressor uses a single tree.\n",
    "     - Overfitting: Random Forest is less prone to overfitting due to ensemble averaging and feature randomization, whereas Decision Trees can easily overfit.\n",
    "     - Predictions: Random Forest aggregates predictions from multiple trees, typically producing more accurate and robust results, while Decision Tree Regressor provides predictions from a single tree.\n",
    "\n",
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "\n",
    "\n",
    "   - A6. \n",
    "     Advantages:\n",
    "     - High predictive accuracy.\n",
    "     - Reduced risk of overfitting.\n",
    "     - Robust to outliers and noisy data.\n",
    "     - Handles both numerical and categorical features.\n",
    "     - Provides feature importance rankings.\n",
    "\n",
    "     Disadvantages:\n",
    "     - Complexity and computational cost.\n",
    "     - Lack of interpretability compared to single decision trees.\n",
    "     - May not perform well on small datasets.\n",
    "     - Hyperparameter tuning can be time-consuming.\n",
    "\n",
    "Q7. What is the output of Random Forest Regressor?\n",
    "\n",
    "\n",
    "   - A7. The output of a Random Forest Regressor is a continuous numerical prediction. It provides a predicted numerical value for each input instance in a regression task.\n",
    "\n",
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "   - A8. Yes, Random Forest can be used for classification tasks as well. In classification, it is known as the Random Forest Classifier. It works similarly to the regressor version but predicts class labels or probabilities instead of continuous numerical values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abf323-4a68-4472-8ba4-c8757841ffca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
