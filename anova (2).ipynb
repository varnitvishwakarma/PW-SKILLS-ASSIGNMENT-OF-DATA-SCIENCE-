{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e6967-2d70-4f1b-8dec-feb1c0b5c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "\n",
    "                                                         \n",
    "    \n",
    "                                                        #answer\n",
    "\n",
    "\n",
    "#Analysis of Variance (ANOVA) is a statistical method used to compare the means of three or more groups to determine if there are statistically \n",
    "#significant differences among them. To use ANOVA effectively, several assumptions need to be met. Violations of these assumptions can impact the \n",
    "#validity of the results. The main assumptions for using ANOVA are:\n",
    "\n",
    "#1. **Independence:** The observations within each group should be independent of each other. This means that the measurements in one group should not\n",
    "#be influenced by or related to the measurements in another group. Violation of this assumption can occur in repeated measures designs\n",
    "#or when there's a clustering effect.\n",
    "\n",
    "#2. **Normality:** The data within each group should be approximately normally distributed. This means that the frequency distribution of the data\n",
    "#points in each group should resemble a bell curve. Violation of this assumption can lead to inaccurate p-values and confidence intervals.\n",
    "\n",
    "#3. **Homogeneity of Variance (Homoscedasticity):** The variances of the groups should be roughly equal. This assumption means that the spread or \n",
    "#dispersion of the data in each group should be consistent across all groups. Violation of this assumption can affect the reliability of the F-test \n",
    "#used in ANOVA.\n",
    "\n",
    "#Examples of violations that could impact the validity of ANOVA results:\n",
    "\n",
    "#1. **Non-Independence:** Imagine you are studying the effect of a new teaching method on students' test scores. However, the students' \n",
    "#scores might be influenced by their classmates' scores, leading to violations of the independence assumption. If students in the same class are \n",
    "#more similar to each other than to students in other classes, the assumption of independence is violated.\n",
    "\n",
    "#2. **Non-Normality:** Consider a study comparing the effectiveness of three different pain relievers. If the pain relief scores within each group \n",
    "#do not follow a normal distribution, ANOVA results might not accurately represent the underlying differences. For instance, if the pain relief \n",
    "#scores are skewed, the assumption of normality is violated.\n",
    "\n",
    "#3. **Heterogeneous Variance:** Suppose you are analyzing the income levels of individuals across different regions. If the income variability \n",
    "#is much larger in one region compared to others, the homogeneity of variance assumption is violated. This could lead to unequal contribution of\n",
    "#variances to the overall F-test statistic, affecting the validity of ANOVA results.\n",
    "\n",
    "#When these assumptions are violated, there are alternative statistical methods that can be considered. For example, if the normality assumption \n",
    "#is violated, non-parametric tests like the Kruskal-Wallis test can be used. If the homogeneity of variance assumption is violated, Welch's ANOVA \n",
    "#or other robust methods might be more appropriate. It's important to assess the assumptions and choose the appropriate analysis method accordingly \n",
    "#to ensure accurate and reliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876d572-8ab0-44f0-8b15-debbaee8de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "\n",
    "\n",
    "                                            ##answer\n",
    "    \n",
    "\n",
    "\n",
    "#The three main types of Analysis of Variance (ANOVA) are:\n",
    "\n",
    "#1. **One-Way ANOVA:**\n",
    "   #- **Situation:** One-Way ANOVA is used when you have one independent variable (factor) with three or more levels or groups, and you want \n",
    "   #to determine if there are significant differences among the means of these groups.\n",
    "   #- **Example:** Suppose you want to compare the average test scores of students from different schools (Group A, Group B, Group C) to see \n",
    "   #if there are any significant differences in performance.\n",
    "\n",
    "#2. **Two-Way ANOVA:**\n",
    "   #- **Situation:** Two-Way ANOVA is used when you have two independent variables (factors), each with multiple levels, and you want to \n",
    "   #explore how these factors interact and whether they have significant effects on the dependent variable.\n",
    "   #- **Example:** Imagine you are studying the effects of both diet (Diet A, Diet B) and exercise intensity (Low, Moderate, High) on weight \n",
    "   #loss. Two-Way ANOVA would allow you to assess the individual and combined effects of these two factors.\n",
    "\n",
    "#3. **Three-Way ANOVA:**\n",
    "   #- **Situation:** Three-Way ANOVA extends the concept of Two-Way ANOVA to three independent variables (factors). It's used when you have \n",
    "   # three factors and you want to investigate their main effects and potential interactions on a dependent variable.\n",
    "   #- **Example:** Consider a study examining the effects of different types of fertilizer (Fertilizer X, Y, Z), sunlight exposure \n",
    "   #(Low, Medium, High), and soil pH (Acidic, Neutral, Alkaline) on plant growth. Three-Way ANOVA would help analyze the combined effects of \n",
    "   #these three factors.\n",
    "\n",
    "#It's important to note that ANOVA assumes certain assumptions, as discussed in a previous question. If these assumptions are violated, alternative \n",
    "#methods or transformations might be necessary. Additionally, post hoc tests or pairwise comparisons can be conducted after ANOVA to determine which \n",
    "#specific groups differ significantly from each other.\n",
    "\n",
    "#Remember that the choice of ANOVA type depends on the research question and experimental design. One-Way ANOVA is appropriate when you \n",
    "#have one categorical independent variable, while Two-Way and Three-Way ANOVA are used for more complex experimental designs involving \n",
    "#interactions between multiple independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f010b3a-7ccb-4af8-a574-741f62091826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "                                         \n",
    "    \n",
    "                                                 ##answer\n",
    "    \n",
    "    \n",
    "    \n",
    "#The partitioning of variance in ANOVA refers to the division of the total variance observed in a dataset into different components that can \n",
    "#be attributed to various sources of variation. This concept is crucial because it helps us understand how much of the overall variability in the \n",
    "#data can be explained by the factors under investigation and how much is due to random variability or error. In other words, it breaks down the \n",
    "#total variability into meaningful components that allow us to assess the significance of the effects we are studying.\n",
    "\n",
    "#In ANOVA, the total variance of the dependent variable is divided into two main components:\n",
    "\n",
    "#1. **Between-Group Variance (Treatment Variance):** This variance accounts for the differences among the group means. It reflects the variation \n",
    "#between different levels or groups of the independent variable(s). A larger between-group variance suggests that the means of the groups are more \n",
    "#spread out from each other.\n",
    "\n",
    "#2. **Within-Group Variance (Error Variance):** This variance accounts for the differences within each group. It represents the variation within \n",
    "#each group that cannot be explained by the independent variable(s). It includes measurement error and other sources of random variability.\n",
    "\n",
    "#The idea is that if the between-group variance is much larger than the within-group variance, it indicates that the independent variable(s) are \n",
    "#having a significant effect on the dependent variable. This is what ANOVA aims to test by comparing the sizes of these variances through the F-test.\n",
    "\n",
    "#The partitioning of variance helps researchers understand how the factors they are investigating contribute to the overall variation in the data.\n",
    "#It also provides insights into the relative importance of different sources of variability. This understanding is crucial for interpreting ANOVA \n",
    "#results, making informed decisions about the significance of effects, and drawing valid conclusions about the relationships between variables.\n",
    "\n",
    "#In summary, the partitioning of variance in ANOVA helps us quantify the impact of different factors on the variability of the data, assess their \n",
    "#significance, and make meaningful inferences about the relationships between variables in a controlled and systematic manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e26a153-881a-4250-af40-dd8b8216187d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 1083.3333333333335\n",
      "Explained Sum of Squares (SSE): 863.3333333333333\n",
      "Residual Sum of Squares (SSR): 220.0\n",
      "F-statistic: 23.545454545454543\n",
      "p-value: 7.013962625523895e-05\n"
     ]
    }
   ],
   "source": [
    "#Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "#sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = np.array([15, 18, 21, 24, 27])\n",
    "group2 = np.array([30, 32, 34, 36, 38])\n",
    "group3 = np.array([10, 13, 16, 19, 22])\n",
    "\n",
    "# Combine data from all groups\n",
    "all_data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "sse = len(group1) * (group1_mean - overall_mean)**2 + \\\n",
    "      len(group2) * (group2_mean - overall_mean)**2 + \\\n",
    "      len(group3) * (group3_mean - overall_mean)**2\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = np.sum((group1 - group1_mean)**2) + \\\n",
    "      np.sum((group2 - group2_mean)**2) + \\\n",
    "      np.sum((group3 - group3_mean)**2)\n",
    "\n",
    "# Degrees of freedom\n",
    "total_df = len(all_data) - 1\n",
    "between_groups_df = 3 - 1\n",
    "within_groups_df = len(all_data) - 3\n",
    "\n",
    "# Calculate the Mean Square for between groups (MSB) and within groups (MSW)\n",
    "msb = sse / between_groups_df\n",
    "msw = ssr / within_groups_df\n",
    "\n",
    "# Calculate the F-statistic\n",
    "f_statistic = msb / msw\n",
    "\n",
    "# Calculate the p-value using the F-distribution\n",
    "p_value = 1 - stats.f.cdf(f_statistic, between_groups_df, within_groups_df)\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735d38af-77f1-42dc-bcef-18cca589f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sum_sq   df         F    PR(>F)\n",
      "C(FactorA)      263.904382  2.0  7.330677  0.070008\n",
      "C(FactorB)        0.551724  1.0  0.030651  0.872170\n",
      "C(Interaction)  302.000000  5.0  3.355556  0.173957\n",
      "Residual         54.000000  3.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {'FactorA': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "        'FactorB': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X'],\n",
    "        'DependentVariable': [15, 18, 21, 24, 27, 30, 10, 13, 16]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create an interaction term\n",
    "df['Interaction'] = df['FactorA'].astype(str) + '*' + df['FactorB']\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'DependentVariable ~ C(FactorA) + C(FactorB) + C(Interaction)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6930e899-9f79-4dae-b9f6-eb8fe0e0e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the \n",
    "#differences between the groups, and how would you interpret these results?\n",
    "\n",
    "\n",
    "                                                  ##answer\n",
    "\n",
    "#In a one-way ANOVA, the F-statistic is used to test whether there are significant differences in the means of the groups being compared. \n",
    "#The p-value associated with the F-statistic indicates the probability of observing such a result (or more extreme) under the assumption that \n",
    "#there are no true differences between the group means.\n",
    "\n",
    "#In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how you can interpret these results:\n",
    "\n",
    "#1. **F-Statistic:** The F-statistic measures the ratio of the variation between group means to the variation within groups. A larger \n",
    "#F-statistic suggests that the differences between group means are relatively large compared to the variation within each group.\n",
    "\n",
    "#2. **p-value:** The p-value is the probability of observing the obtained F-statistic (or a more extreme value) if the null hypothesis is true. \n",
    "#In this context, the null hypothesis is that there are no significant differences between the group means. A p-value of 0.02 means that if there\n",
    "#were no real differences between the groups, you would expect to see an F-statistic as extreme as 5.23 or more extreme in only 2% of cases.\n",
    "\n",
    "#Interpretation:\n",
    "\n",
    "#With a p-value of 0.02, which is less than the commonly used significance level of 0.05, you have evidence to reject the null hypothesis. \n",
    "#This suggests that there are likely significant differences between at least some of the group means. In other words, there is enough statistical \n",
    "#evidence to conclude that the groups are not all the same.\n",
    "\n",
    "#However, the exact interpretation of which specific groups are different requires additional post hoc tests or pairwise comparisons. \n",
    "#These tests will help identify which groups have statistically significant differences in means.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc7c0db-bb74-492e-b4bb-fe751083877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to \n",
    "#handle missing data?\n",
    "\n",
    "                                                        ##answer\n",
    "    \n",
    "\n",
    "    \n",
    "#Handling missing data in a repeated measures ANOVA is important to ensure the accuracy and reliability of your results. Missing data can arise \n",
    "#for various reasons, such as participant dropout, equipment malfunction, or data recording errors. There are several methods to handle\n",
    "#missing data, each with its own advantages and potential consequences. Some common methods include:\n",
    "\n",
    "#1. **Complete Case Analysis (Listwise Deletion):** This approach involves removing all cases with missing data for any of the variables involved\n",
    "#in the analysis. While it's simple, it can lead to reduced sample size and biased results if the missing data is not random and is related to \n",
    "#the variables being studied. This can result in loss of statistical power and potentially biased parameter estimates.\n",
    "\n",
    "#2. **Mean Imputation:** In this method, missing values are replaced with the mean of the available data for that variable. While it's simple,\n",
    "#it can lead to underestimation of standard errors and correlations, potentially distorting the statistical significance of results.\n",
    "\n",
    "#3. **Last Observation Carried Forward (LOCF) or Next Observation Carried Backward (NOCB):** These methods involve using the last available \n",
    "#observation for missing data in subsequent time points (LOCF) or using the next available observation for preceding time points (NOCB). \n",
    "#However, they can lead to biased estimates, especially if the missing data is not missing at random.\n",
    "\n",
    "#4. **Linear Interpolation:** Linear interpolation involves estimating missing values based on the linear relationship between neighboring \n",
    "#time points. This can provide better estimates for continuous variables, but it assumes a linear relationship, which may not hold true in all cases.\n",
    "\n",
    "#5. **Multiple Imputation:** Multiple imputation involves creating multiple plausible imputed datasets and analyzing each separately before\n",
    "#combining the results. This method accounts for uncertainty due to missing data and provides more accurate estimates and valid statistical \n",
    "#inferences. However, it can be computationally intensive.\n",
    "\n",
    "#6. **Model-Based Methods:** These methods involve using a statistical model to predict missing values based on observed data. \n",
    "#For repeated measures ANOVA, you could use a mixed-effects model to handle missing data while accounting for within-subject correlations. \n",
    "#These methods can provide accurate results when the model assumptions are met.\n",
    "\n",
    "#Choosing the appropriate method to handle missing data depends on the nature of the data and the reasons for missingness. \n",
    "#It's important to consider potential consequences when choosing a method. Using inappropriate methods can lead to biased results, \n",
    "#inflated or deflated significance levels, and distorted conclusions. Therefore, it's recommended to carefully evaluate the missing \n",
    "#data mechanism and consider the assumptions and potential limitations of the chosen method. Multiple imputation or model-based approaches\n",
    "#are generally preferred when possible, as they can provide more robust and accurate results compared to simpler methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35687e25-7e30-4480-90a9-b2e8ffac933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where \n",
    "#a post-hoc test might be necessary.\n",
    "\n",
    "\n",
    "                                                          ##answer\n",
    "    \n",
    "    \n",
    "#Post hoc tests are used after conducting an Analysis of Variance (ANOVA) to determine which specific group differences are significant when a \n",
    "#significant overall  ANOVA result is obtained. These tests help to pinpoint where the differences lie among the groups. There are several \n",
    "#post hoc tests available, and the choice of which one to use depends on the specific research question and the design of the experiment. \n",
    "#Some common post hoc tests include:\n",
    "\n",
    "#1. **Tukey's Honestly Significant Difference (HSD):** Tukey's HSD is a conservative test that compares all possible pairs of group means. \n",
    "#It controls the overall Type I error rate (the probability of making a false positive conclusion across all pairwise comparisons).\n",
    "\n",
    "#2. **Bonferroni Correction:** This method involves adjusting the significance level (alpha) to account for multiple comparisons. \n",
    "#It's more conservative than other post hoc tests and is used to control the familywise error rate.\n",
    "\n",
    "#3. **Dunnett's Test:** This test is used when comparing multiple treatment groups to a single control group. It adjusts the significance \n",
    "#level to control the overall Type I error rate for this specific situation.\n",
    "\n",
    "#4. **LSD (Least Significant Difference):** The LSD test compares individual group means and controls the probability of making a Type I \n",
    "#error for each comparison. However, it does not control the overall Type I error rate for multiple comparisons.\n",
    "\n",
    "#5. **Scheffe's Test:** Scheffe's test is more conservative and suitable for situations where there are complex contrasts or multiple \n",
    "#comparisons. It controls the familywise error rate for all possible comparisons.\n",
    "\n",
    "#6. **Fisher's Least Significant Difference (LSD):** Similar to Tukey's HSD, Fisher's LSD tests all pairwise differences but is less conservative. \n",
    "#It's commonly used when the assumption of homogeneity of variances is met.\n",
    "\n",
    "#Here's an example of when a post hoc test might be necessary:\n",
    "\n",
    "#**Scenario:** Imagine you conducted a one-way ANOVA to compare the effects of three different teaching methods (Method A, Method B, Method C) on \n",
    "#students' exam scores. The ANOVA result indicates that there is a significant difference among the groups.\n",
    "\n",
    "#**Post Hoc Test:** After obtaining a significant ANOVA result, you decide to conduct a post hoc test to determine which specific pairs of \n",
    "#teaching methods have significantly different effects on exam scores.\n",
    "\n",
    "#**Choice of Test:** You might choose Tukey's HSD to control the overall Type I error rate while comparing all pairs of teaching methods.\n",
    "#This would allow you to identify which specific teaching methods lead to significant differences in exam scores.\n",
    "\n",
    "#In this scenario, the post hoc test helps you go beyond the ANOVA result and provides more detailed insights into the differences between\n",
    "#the individual teaching methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba76874-9214-4970-af33-dee41299376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 97.4925070246645\n",
      "p-value: 4.446737064435793e-13\n"
     ]
    }
   ],
   "source": [
    "#Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly \n",
    "#assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean\n",
    "#weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for weight loss of participants in each diet group\n",
    "diet_a = np.array([5.3, 4.8, 6.1, 5.7, 4.9, 5.5, 4.4, 5.9, 6.3, 5.2])\n",
    "diet_b = np.array([3.5, 4.2, 3.9, 4.8, 3.2, 4.0, 4.5, 3.7, 3.9, 4.1])\n",
    "diet_c = np.array([2.1, 1.8, 2.5, 2.9, 2.0, 2.4, 2.7, 2.3, 2.8, 2.2])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff05bc36-1e1c-4e80-a6af-3213a587a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   sum_sq   df         F    PR(>F)\n",
      "C(Software)     27.153472  2.0  1.227368  0.357399\n",
      "C(Experience)    0.060114  1.0  0.005434  0.943631\n",
      "C(Interaction)  37.396667  5.0  0.676149  0.657795\n",
      "Residual        66.370000  6.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "##Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "#complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "#randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "#complete the task. import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {'Software': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "        'Experience': ['Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced',\n",
    "                       'Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced'],\n",
    "        'Time': [15.2, 18.5, 20.1, 22.4, 12.7, 14.3, 16.8, 19.2, 21.0, 13.5, 15.9, 17.2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create an interaction term\n",
    "df['Interaction'] = df['Software'] + '*' + df['Experience']\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Time ~ C(Software) + C(Experience) + C(Interaction)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe287f1-9661-4020-8bab-1e3e3b4f4cd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2189935705.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Q11. An educational researcher is interested in whether a new teaching method improves student test\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "#scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "#experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "#two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "#between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "#group(s) differ significantly from each other.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d895df-cc43-47db-aedb-cf8186444515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "#retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "#on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "#significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "#hoc test to determine which store(s) differ significantly from each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
