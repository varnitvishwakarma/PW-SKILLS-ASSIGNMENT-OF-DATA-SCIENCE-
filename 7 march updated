Q1. What are the three measures of central tendency?

1. mean
2. median 
3 .mode 



Q2. What is the difference between the mean, median, and mode? How are they used to measure the central tendency of a dataset?

The mean, median, and mode are all measures of central tendency used to describe the center or typical value of a dataset. However, they differ in how they are calculated and what aspect of the data they represent.

1. Mean: The mean, also known as the average, is calculated by summing up all the values in a dataset and dividing the sum by the number of values. It represents the arithmetic center of the data. The formula for calculating the mean is:

   mean = sum of all values / number of values
​
2. Median: The median is the middle value of a dataset when it is arranged in ascending or descending order. If the dataset has an odd number of values, the median is the middle value itself. If the dataset has an even number of values, the median is the average of the two middle values. The median is not affected by extreme values because it only considers the position of values, not their actual magnitude.
​
​
3. Mode: The mode is the value that appears most frequently in a dataset. It represents the most common value or values. Unlike the mean and median, the mode can be applied to both numerical and categorical data. A dataset can have no mode (when all values occur with equal frequency), a single mode, or multiple modes.
​
These measures of central tendency provide different insights into the dataset. The mean is useful for understanding the average value, the median helps identify the middle value, and the mode reveals the most common value(s). They are all used to summarize and describe data in various fields, such as statistics, economics, and social sciences.






Q3. Measure the three measures of central tendency for the given height data:

import numpy as np 
from scipy import stats as sc
​
​
data= [178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]
​
print("mean",np.mean(data))
print("median",np.median(data))
sc.mode(data)
mean 177.01875
median 177.0
/tmp/ipykernel_70/519615064.py:9: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  sc.mode(data)
ModeResult(mode=array([177.]), count=array([3]))






Q4. Find the standard deviation for the given data:

data
data=[178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]
​
np.std(data)
1.7885814036548633







Q5. How are measures of dispersion such as range, variance, and standard deviation used to describe the spread of a dataset? Provide an example.

Measures of dispersion, such as range, variance, and standard deviation, are used to describe the spread or variability of a dataset. They provide information about how spread out the values are from the central tendency measures like mean or median. Here's how they are used:
​
1. Range: The range is the simplest measure of dispersion and represents the difference between the largest and smallest values in a dataset. It provides an idea of the spread of values in the dataset but doesn't take into account the distribution of values between the extremes.
​
   For example, consider the dataset: 10, 20, 30, 40, and 100. The range would be calculated as the difference between the largest value (100) and the smallest value (10), resulting in a range of 90.
​
   However, the range can be influenced by extreme values and may not provide a complete picture of the variability if the dataset contains outliers.
​
2. Variance: The variance measures the average squared deviation of each value from the mean. It provides a more comprehensive measure of dispersion by considering all the values in the dataset.
​
   To calculate the variance, you subtract the mean from each value, square the result, sum up all the squared deviations, and divide by the number of values. The formula for variance is:
​
   variance = sum of (value - mean)^2 / number of values
​
   For example, using the dataset 10, 20, 30, 40, and 100, the mean is 40. The squared deviations from the mean are: (10-40)^2 = 900, (20-40)^2 = 400, (30-40)^2 = 100, (40-40)^2 = 0, (100-40)^2 = 3600. The sum of squared deviations is 5000. Dividing by the number of values (5), the variance would be 1000.
​
   The variance is useful for understanding the overall spread of the dataset, but since it involves squared deviations, its value is not in the same unit as the original data.
​
3. Standard Deviation: The standard deviation is the square root of the variance. It provides a measure of dispersion in the same unit as the original data and is widely used because of its interpretability and mathematical properties.
​
   To calculate the standard deviation, you take the square root of the variance. In the previous example, the variance was calculated as 1000. Taking the square root of 1000 gives a standard deviation of approximately 31.62.
​
   The standard deviation is helpful for understanding the typical distance between each data point and the mean. It quantifies the average amount of dispersion and is widely used in various fields, such as finance, biology, and psychology, to describe the variability of data.







Q6. What is a Venn diagram?

A Venn diagram is a graphical representation that illustrates the relationships and similarities between different sets or groups of objects or elements. It consists of overlapping circles or other shapes, with each circle representing a set and the overlapping areas indicating the elements that belong to multiple sets.








Q7. For the two given sets A = (2,3,4,5,6,7) & B = (0,2,6,8,10). Find: (i) A B (ii) A ⋃ B

A intersection B : (2,6)
A union B : (2,3,4,5,6,7,10,8,0)







Q8. What do you understand about skewness in data?

Skewness in data refers to the asymmetry or lack of symmetry in the distribution of values. It is a measure of the departure of a dataset from a symmetrical or normally distributed pattern.
​
In a symmetrical distribution, the data is evenly distributed around the mean, with the left and right tails of the distribution being roughly equal. However, in skewed distributions, the data is shifted towards one side, resulting in an imbalance.







Q9. If a data is right skewed then what will be the position of median with respect to mean?

In a right-skewed distribution, the tail of the distribution extends towards the right side, indicating that the data has a few large values that pull the mean towards the right. In such cases, the position of the median will typically be less than the mean.
​
To understand why this happens, consider the characteristics of the mean and median:
​
- Mean: The mean is sensitive to extreme values or outliers in the dataset. Since right-skewed distributions have a few large values on the right side, these outliers have a greater impact on pulling the mean towards the right. As a result, the mean tends to be greater than the median.
​
- Median: The median, on the other hand, is not influenced by the specific values in the tails of the distribution, but rather focuses on the middle value(s). Since right-skewed distributions have a longer right tail, the median tends to be closer to the left, where the bulk of the data is concentrated.
​
Therefore, in a right-skewed distribution, the median will generally be positioned to the left of the mean. This pattern reflects the fact that the median is less affected by extreme values and represents the central value of the dataset without being pulled by outliers in the tail.








Q10. Explain the difference between covariance and correlation. How are these measures used in statistical analysis?

Covariance and correlation are both measures that describe the relationship between two variables in statistical analysis. While they are related, they have distinct differences in terms of interpretation and scale:
​
Covariance:
- Covariance measures the direction and strength of the linear relationship between two variables.
- It provides information about how changes in one variable are associated with changes in another variable.
- The value of covariance can range from negative infinity to positive infinity.
- A positive covariance indicates a positive relationship, meaning that when one variable increases, the other tends to increase as well. A negative covariance indicates a negative relationship, meaning that when one variable increases, the other tends to decrease.
- However, covariance does not provide a standardized measure, so it can be difficult to interpret the strength or magnitude of the relationship.
​
Correlation:
- Correlation also measures the direction and strength of the linear relationship between two variables.
- It provides a standardized measure that ranges between -1 and +1, allowing for easier interpretation and comparison.
- A correlation coefficient of +1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.
- The correlation coefficient is not affected by changes in scale or units of the variables, making it a more reliable measure for comparing relationships between different pairs of variables.
- Correlation is more commonly used than covariance because it provides a standardized measure that is easier to interpret and compare across different datasets.
​
Both covariance and correlation are used in statistical analysis to assess the relationship between variables and to understand how changes in one variable may be associated with changes in another. They are commonly used in fields such as finance, economics, social sciences, and data analysis to identify patterns, make predictions, and guide decision-making processes.









Q11. What is the formula for calculating the sample mean? Provide an example calculation for a dataset.

The formula for calculating the sample mean is as follows:
​
Sample Mean = (Sum of all values in the dataset) / (Number of values in the dataset)
​
To calculate the sample mean, you add up all the values in the dataset and divide the sum by the number of values.
​
Let's consider an example calculation for a dataset:
​
Dataset: 10, 15, 20, 25, 30
​
To find the sample mean, we add up all the values and divide by the number of values:
​
Sum of values = 10 + 15 + 20 + 25 + 30 = 100
​
Number of values = 5
​
Sample Mean = 100 / 5 = 20
​
Therefore, the sample mean for the given dataset is 20.















Q12. For a normal distribution data what is the relationship between its measure of central tendency?

For a normal distribution, the measures of central tendency, namely the mean, median, and mode, are all equal and coincide at the center of the distribution. In other words, they have the same value.
​
This property holds true because the normal distribution is symmetric around its mean. The mean represents the arithmetic average of the data points, the median represents the middle value, and the mode represents the most frequent value. Since the distribution is symmetrical, the values at the center of the distribution are the same, resulting in equal measures of central tendency.
​
So, for a normal distribution:
​
- The mean, median, and mode are all equal.
- They are located at the center of the distribution.
- The distribution is perfectly symmetrical around this central value.
​
This relationship between the measures of central tendency in a normal distribution is a key characteristic of this type of distribution and allows for a concise and reliable summary of the data's central location.










Q13. How is covariance different from correlation?

Covariance measures the direction and strength of the linear relationship between two variables, whereas correlation provides a standardized measure of the same relationship. Covariance is affected by the scale of the variables, making it difficult to interpret. Correlation ranges between -1 and +1, is unaffected by scale, and is easier to interpret and compare.














Q14. How do outliers affect measures of central tendency and dispersion? Provide an example.

Outliers can significantly impact measures of central tendency and dispersion. Measures such as mean and standard deviation are particularly sensitive to outliers.
​
For central tendency, outliers can significantly influence the mean, pulling it towards their extreme values. The median, being less affected by extreme values, provides a more robust measure of central tendency.
​
Regarding dispersion, outliers can inflate the range, which is the difference between the maximum and minimum values. Similarly, outliers can increase the variance and standard deviation, as these measures consider the squared differences from the mean.
​
For example, consider a dataset of exam scores: 85, 90, 92, 94, 97, 100, and an outlier of 200. The mean would be significantly affected, resulting in a higher value. The range would also be impacted, increasing from 15 to 115 due to the outlier's influence. Similarly, the variance and standard deviation would be inflated, reflecting the greater spread caused by the outlier.
​

