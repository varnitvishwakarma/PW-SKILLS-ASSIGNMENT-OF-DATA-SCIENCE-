{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292a3ff9-a931-42d8-969c-893a6b8cb68b",
   "metadata": {},
   "source": [
    "## 2 MAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2068f-25dc-4b5c-8688-ff76f33a9d1f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q1. **What is anomaly detection and its purpose?**\n",
    "   - Anomaly detection is a data analysis technique used to identify and flag observations or data points that deviate significantly from the expected or normal behavior within a dataset.\n",
    "   - Its primary purpose is to detect unusual or rare events or patterns that may indicate potential issues, anomalies, or outliers. Anomalies can be indicative of errors, fraud, security breaches, or other important phenomena that require attention. By identifying anomalies, organizations can take corrective actions and prevent potential problems.\n",
    "\n",
    "Q2. **What are the key challenges in anomaly detection?**\n",
    "   - Anomaly detection faces several challenges, including:\n",
    "     - Lack of labeled data: In many cases, anomalies are rare, making it difficult to obtain sufficient labeled examples for training.\n",
    "     - Imbalanced data: Anomalies often represent a small portion of the dataset, leading to class imbalance issues.\n",
    "     - Identifying various anomaly types: Anomalies can take various forms, including point, contextual, and collective anomalies, each requiring different approaches.\n",
    "     - High-dimensional data: In high-dimensional spaces, data points become sparse, making anomaly detection computationally challenging.\n",
    "     - Interpretability: Understanding why an algorithm flagged a particular data point as an anomaly can be challenging, especially in complex datasets.\n",
    "\n",
    "Q3. **How does unsupervised anomaly detection differ from supervised anomaly detection?**\n",
    "   - Unsupervised anomaly detection operates without labeled data, relying solely on data characteristics to identify anomalies. It's used when there's limited prior knowledge about what constitutes an anomaly.\n",
    "   - Supervised anomaly detection, on the other hand, uses labeled data for training. It learns to differentiate between normal and anomalous data points during training and can classify new data points based on this learned knowledge.\n",
    "\n",
    "Q4. **What are the main categories of anomaly detection algorithms?**\n",
    "   - Anomaly detection algorithms fall into several categories:\n",
    "     - Statistical Methods: These use statistical techniques like Z-scores or Gaussian distributions to model normal data and detect deviations.\n",
    "     - Machine Learning-Based Methods: These employ supervised or unsupervised machine learning algorithms, including Isolation Forest and Local Outlier Factor.\n",
    "     - Distance-Based Methods: These measure distances between data points and use thresholds or clustering to identify anomalies.\n",
    "     - Density-Based Methods: They focus on regions of low data density to flag anomalies.\n",
    "     - Time Series Anomaly Detection: Specialized methods for identifying anomalies in time series data.\n",
    "\n",
    "Q5. **What are the main assumptions in distance-based anomaly detection?**\n",
    "   - Distance-based methods assume that anomalies are typically distant from normal data points in feature space. They also assume that normal data points are densely clustered together, while anomalies are isolated or sparsely distributed. Additionally, these methods rely on an appropriate distance metric for measuring dissimilarity between data points and require suitable parameter settings, such as the number of neighbors in KNN.\n",
    "\n",
    "Q6. **How does LOF compute anomaly scores?**\n",
    "   - The Local Outlier Factor (LOF) algorithm calculates anomaly scores by comparing the local density of a data point to the densities of its k-nearest neighbors. A point with a significantly lower density than its neighbors is considered an anomaly, as it is in a region of lower data density, indicating its deviation from the norm.\n",
    "\n",
    "Q7. **What are the key parameters of the Isolation Forest algorithm?**\n",
    "   - The Isolation Forest algorithm's key parameters include the number of trees (n_estimators) and the maximum depth (max_depth) for each tree. These parameters control the algorithm's effectiveness and computational complexity.\n",
    "\n",
    "Q8. **Anomaly score using KNN with K=10 for 2 neighbors of the same class within radius 0.5?**\n",
    "   - Anomaly scores in KNN depend on several factors, including the distance to neighbors and their class labels. In this case, having only 2 neighbors within a small radius of 0.5 does not provide sufficient information to determine an anomaly score without knowledge of the specific data and the chosen distance metric.\n",
    "\n",
    "Q9. **Using Isolation Forest with 100 trees and a data point with an average path length of 5.0 compared to the tree average path length?**\n",
    "   - Anomalies in Isolation Forest typically have shorter average path lengths compared to the average path length of trees. In this scenario, a data point with an average path length of 5.0 is likely less anomalous than the average anomaly detected by the forest, but the specific anomaly score would depend on the distribution of path lengths in the dataset and the behavior of the isolation trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
